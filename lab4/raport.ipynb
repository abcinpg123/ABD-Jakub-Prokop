{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Laboratorium Analiza i bazy danych </center>\n",
    "\n",
    "## <center>Łączenie tabel, podzapytania i funkcje agregujące</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowe tabele obrazujące łączenie\n",
    "\n",
    "Do zobrazowania operacji łączenia zostaną użyte tabele:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE shape_a (\n",
    "    id INT PRIMARY KEY,\n",
    "    shape VARCHAR (100) NOT NULL\n",
    ");\n",
    " \n",
    "CREATE TABLE shape_b (\n",
    "    id INT PRIMARY KEY,\n",
    "    shape VARCHAR (100) NOT NULL\n",
    ");\n",
    "```\n",
    " \n",
    "Polecenie CREATE TABLE tworzy tabelę o zadanej nazwie i strukturze. Ogólna postać to:\n",
    "```sql\n",
    "CREATE TABLE tab_name (\n",
    "    col_name1 data_type constrain,\n",
    "    col_name1 data_type constrain,\n",
    "    ...\n",
    ");\n",
    "```\n",
    "Należy uzupełnić ją danymi:\n",
    "```sql\n",
    "INSERT INTO shape_a (id, shape)\n",
    "VALUES\n",
    "    (1, 'Trójkąt'),\n",
    "    (2, 'Kwadrat'),\n",
    "    (3, 'Deltoid'),\n",
    "    (4, 'Traper');\n",
    " \n",
    "INSERT INTO shape_b (id, shape)\n",
    "VALUES\n",
    "    (1, 'Kwadrat'),\n",
    "    (2, 'Trójkąt'),\n",
    "    (3, 'Romb'),\n",
    "    (4, 'Równoległobok');\n",
    "```\n",
    "Komenda INSERT INTO pozwala na dodanie do tabeli rekordów. Ogólna postać to:\n",
    "\n",
    "```sql\n",
    "INSERT INTO tab_name (col1_name, col2_name2, ...) \n",
    "VALUES\n",
    "    (val1_col1, val2_col2),\n",
    "    (val2_col1, val2_col2),\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner join \n",
    "\n",
    "Jest to podstawowy rodzaj złączenie. Ten sposób złączenia wybiera  te wiersze, dla których warunek złączenia jest spełniony. W żadnej z łączonych tabel kolumna użyta do łączenia nie może mieć wartości NULL. \n",
    "\n",
    "#### Przykład:\n",
    "```sql\n",
    "SELECT\n",
    "    a.id id_a,\n",
    "    a.shape shape_a,\n",
    "    b.id id_b,\n",
    "    b.shape shape_b\n",
    "FROM\n",
    "    shape_a a\n",
    "INNER JOIN shape_b b ON a.shape = b.shape;\n",
    "```\n",
    "W zapytaniu powyżej użyto *aliasów* nazw tabel i column wynikowych, jest to szczególnie przydatne przy długich nazwach tabel i wprowadza czytelność w zapytaniu.\n",
    "\n",
    "#### Wynik:\n",
    "|id_a|shape_a|id_b|shape_b|\n",
    "|-|-|-|-|\n",
    "|1|Trójkąt|2|Trójkąt|\n",
    "|2|Kwadrat|1|Kwadrat|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTER JOIN\n",
    "\n",
    "Istnieją trzy rodzaje złączeń OUTER:\n",
    "- LEFT OUTER JOIN,\n",
    "- RIGHT OUTER JOIN,\n",
    "- FULL OUTER JOIN.\n",
    "\n",
    "### LEFT OUTER JOIN\n",
    "\n",
    "Ten rodzaj złączenie zwróci wszystkie rekordy z lewej tablicy i dopasuje do nich rekordy z prawej tablicy które spełniją zadany warunek złączenia. Jeżeli w prawej tablicy nie występują rekordy spełnijące warunek złączenia z lewą w ich miejscu pojawią się wartości NULL.\n",
    "\n",
    "#### Przykład 1:\n",
    "```sql\n",
    "SELECT\n",
    "    a.id id_a,\n",
    "    a.shape shape_a,\n",
    "    b.id id_b,\n",
    "    b.shape shape_b\n",
    "FROM\n",
    "    shape_a a\n",
    "LEFT JOIN shape_b b ON a.shape = b.shape;\n",
    "```\n",
    "#### Wynik:\n",
    "|id_a|shape_a|id_b|shape_b|\n",
    "|-|-|-|-|\n",
    "|1|Trójkąt|2|Trójkąt|\n",
    "|2|Kwadrat|1|Kwadrat|\n",
    "|3|Deltoid|NULL|NULL|\n",
    "|4|Traper|NULL|NULL|\n",
    "\n",
    "#### Przykład 2:\n",
    "```sql\n",
    "SELECT\n",
    "    b.id id_b,\n",
    "    b.shape shape_b,\n",
    "    a.id id_a,\n",
    "    a.shape shape_a   \n",
    "FROM\n",
    "    shape_b b\n",
    "LEFT JOIN shape_a a ON a.shape = b.shape;\n",
    "```\n",
    "#### Wynik:\n",
    "|id_a|shape_a|id_b|shape_b|\n",
    "|-|-|-|-|\n",
    "|1|Kwadrat|2|Kwadrat|\n",
    "|2|Trójkąt|1|Trójkąt|\n",
    "|3|Romb|NULL|NULL|\n",
    "|4|Równoległobok|NULL|NULL|\n",
    "\n",
    "### RIGHT OUTER JOIN\n",
    "\n",
    "Działa jak left outer join z tym, że prawa tablica w zapytaniu jest brana w całości.\n",
    "\n",
    "#### Przykład:\n",
    "```sql\n",
    "SELECT\n",
    "    a.id id_a,\n",
    "    a.shape shape_a,\n",
    "    b.id id_b,\n",
    "    b.shape shape_b\n",
    "FROM\n",
    "    shape_a a\n",
    "RIGHT JOIN shape_b b ON a.shape = b.shape;\n",
    "```\n",
    "\n",
    "#### Wynik:\n",
    "|id_a|shape_a|id_b|shape_b|\n",
    "|-|-|-|-|\n",
    "|2|Kwadrat|1|Kwadrat|\n",
    "|1|Trójkąt|2|Trójkąt|\n",
    "|NULL|NULL|3|Romb|\n",
    "|NULL|NULL|4|Równoległobok|\n",
    "\n",
    "\n",
    "### FULL OUTER JOIN\n",
    "\n",
    "Jest złączeniem które zwraca:\n",
    "- wiersze dla których warunek złączenia jest spełniony,\n",
    "- wiersze z lewej tabeli dla których nie ma odpowiedników w prawej,\n",
    "- wiersze z prawej tabeli dla których nie ma odpowiedników w lewej. \n",
    "\n",
    "#### Przykład:\n",
    "```sql\n",
    "SELECT\n",
    "    a.id id_a,\n",
    "    a.shape shape_a,\n",
    "    b.id id_b,\n",
    "    b.shape shape_b\n",
    "FROM\n",
    "    shape_a a\n",
    "FULL JOIN shape_b b ON a.shape = b.shape;\n",
    "```\n",
    "|id_a|shape_a|id_b|shape_b|\n",
    "|-|-|-|-|\n",
    "|1|Trójkąt|2|Trójkąt|\n",
    "|2|Kwadrat|1|Kwadrat|\n",
    "|3|Deltoid\"|NULL|NULL|\n",
    "|4|Traper|NULL|NULL|\n",
    "|NULL|NULL|3|Romb|\n",
    "|NULL|NULL|4|Równoległobok|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podzapytania\n",
    "\n",
    "Podzapytanie zagnieżdżone SELECT znajduje się wewnątrz zewnętrznego zapytania SELECT, np. po klauzuli WHERE, HAVING lub FROM. W przypadku tego rodzaju zapytań w pierwszej kolejności wykonywane są wewnętrzne zapytania SELECT, a ich wynik jest wykorzystywany do zewnętrznego zapytania SELECT. Stąd łatwo zuważyć, że mogą one służyć do poprawy wydajności obsługi zapytania. Należy dobierać podzapytania tak by najbardziej zagnieżdżone podzapytanie zawierało najmniejszy zbiór poszukiwań. \n",
    "\n",
    "#### Przykład:\n",
    "Jeżeli chcemy znaleźć w bazie informację o tytułach filmów zwróconych w zadanym okresie możemy wykonać następujące zapytanie:\n",
    "```sql\n",
    "SELECT\n",
    "   film_id,\n",
    "   title\n",
    "FROM\n",
    "   film\n",
    "WHERE\n",
    "   film_id IN (\n",
    "      SELECT\n",
    "         inventory.film_id\n",
    "      FROM\n",
    "         rental\n",
    "      INNER JOIN inventory ON inventory.inventory_id = rental.inventory_id\n",
    "      WHERE\n",
    "         return_date BETWEEN '2005-05-29'\n",
    "      AND '2005-05-30'\n",
    "   );\n",
    "```\n",
    "\n",
    "#### Wynik\n",
    "|film_id|title|\n",
    "|-|-|\n",
    "|307|Fellowship Autumn|\n",
    "|255|Driving Polish|\n",
    "|388|Gunfight Moon|\n",
    "|130|Celebrity Horn|\n",
    "|563|Massacre Usual|\n",
    "|397|Hanky October|\n",
    "|...|...|\n",
    "\n",
    "### Używanie podzapytań\n",
    "\n",
    "Pod zapytania mogą być używane w :\n",
    "- SELECT,\n",
    "- UPDATE,\n",
    "- DELETE,\n",
    "- Funkcjach agregujących,\n",
    "- Do definiowania tabel tymczasowych.\n",
    "\n",
    "Używając podzapytań zapytania SQL szybko mogą stać się mało czytelne. Przez co będą trudne w zrozumieniu i późniejszym utrzymaniu. W celu analizy zapytań można użyć klauzuli __EXPLAIN__, która przeanalizuje zapytanie. Klauzula ta może służyć również do porównywania wydajności zapytań\n",
    "\n",
    "#### Przykład:\n",
    "```sql\n",
    "EXPLAIN SELECT\n",
    "   *\n",
    "FROM\n",
    "   film\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje agregujące\n",
    "\n",
    "Funkcje agregujące wykonują obliczenia na zestawie wierszy i zwracają pojedynczy wiersz. PostgreSQL udostępnia wszystkie standardowe funkcje agregujące SQL w następujący sposób:\n",
    "- AVG () - zwraca średnią wartość.\n",
    "- COUNT () - zwraca liczbę wartości.\n",
    "- MAX () - zwraca maksymalną wartość.\n",
    "- MIN () - zwraca minimalną wartość.\n",
    "- SUM () - zwraca sumę wszystkich lub różnych wartości.\n",
    "\n",
    "Pełna lista funkcji agregującej: https://www.postgresql.org/docs/9.5/functions-aggregate.html\n",
    "\n",
    "Często używamy funkcji agregujących z klauzulą GROUP BY w instrukcji SELECT. W tych przypadkach klauzula GROUP BY dzieli zestaw wyników na grupy wierszy i funkcja agregująca wykonuje obliczenia dla każdej grupy, np. maksimum, minimum, średnia itp. Funkcji agregujących można używać funkcji agregujących jako wyrażeń tylko w następujących klauzulach: SELECT i HAVING.\n",
    "\n",
    "### GROUP BY\n",
    "Klauzula GROUP BY dzieli wiersze zwrócone z instrukcji SELECT na grupy. Dla  każdej grupy można zastosować funkcję agregującą, np. SUM aby obliczyć sumę pozycji lub\n",
    "COUNT aby uzyskać liczbę elementów w grupach.\n",
    "\n",
    "Poniższa instrukcja ilustruje składnię klauzuli GROUP BY:\n",
    "```sql\n",
    "SELECT \n",
    "    column_1, \n",
    "    aggregate_function(column_2)\n",
    "FROM \n",
    "    tbl_name\n",
    "GROUP BY \n",
    "    column_1;\n",
    "```\n",
    "Klauzula GROUP BY musi pojawić się zaraz po klauzuli FROM lub WHERE, n0astępnie GROUP BY zawiera listę  kolumna oddzielonych przecinkami. \n",
    "\n",
    "### HAVING\n",
    "Często używamy klauzuli HAVING w połączeniu z klauzulą GROUP BY do filtrowania wierszy grup\n",
    "które nie spełniają określonego warunku.\n",
    "\n",
    "Poniższa instrukcja ilustruje typową składnię klauzuli HAVING:\n",
    "```sql\n",
    "SELECT\n",
    "    column_1,\n",
    "    aggregate_function (column_2)\n",
    "FROM\n",
    "    tbl_name\n",
    "GROUP BY\n",
    "    column_1\n",
    "HAVING\n",
    "    condition;\n",
    "```\n",
    "Klauzula HAVING ustawia warunek dla wierszy grup utworzonych przez klauzulę GROUP BY.  \n",
    "\n",
    "Klauzula GROUP BY ma zastosowanie, podczas gdy klauzula WHERE określa wcześniej warunki dla poszczególnych wierszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadania wprowadzające\n",
    "Wykonaj zapytania przy użyciu DBMS:  \n",
    "  \n",
    "1. Znajdź listę wszystkich filmów o tej samej długości.\n",
    "2. Znajdź wszystkich klientów mieszkających w tym samym mieście.\n",
    "3. Oblicz średni koszt wypożyczenia wszystkich filmów.\n",
    "4. Oblicz i wyświetl liczbę filmów we wszystkich kategoriach.\n",
    "5. Wyświetl liczbę wszystkich klientów pogrupowanych według kraju.\n",
    "6. Wyświetl informacje o sklepie, który ma więcej niż 100 klientów i mniej niż 300 klientów.\n",
    "7. Wybierz wszystkich klientów, którzy oglądali filmy ponad 200 godzin.\n",
    "8. Oblicz średnią wartość wypożyczenia filmu.\n",
    "9. Oblicz średnią wartość długości filmu we wszystkich kategoriach.\n",
    "10. Znajdź najdłuższe tytuły filmowe we wszystkich kategoriach.\n",
    "11. Znajdź najdłuższy film we wszystkich kategoriach. Porównaj wynik z pkt 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Znajdź listę wszystkich filmów o tej samej długości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 title  length\n",
      "0         Alien Center      46\n",
      "1            Iron Moon      46\n",
      "2        Kwai Homeward      46\n",
      "3     Labyrinth League      46\n",
      "4  Ridgemont Submarine      46\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "\n",
    "connection = pg.connect(host='pgsql-196447.vipserv.org', port=5432, dbname='wbauer_adb', user='wbauer_adb', password='adb2020');\n",
    "df = pd.read_sql('select title, length from film where length = 46',con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Znajdź wszystkich klientów mieszkających w tym samym mieście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first_name last_name   city\n",
      "0      Larry  Thrasher  Adana\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select first_name, last_name, city from customer INNER JOIN address on customer.address_id=address.address_id INNER JOIN city on address.city_id = city.city_id where city='Adana'\",con=connection)\n",
    "print(df)\n",
    "\n",
    "#akurat w Adanie mieszka jeden klient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Oblicz średni koszt wypożyczenia wszystkich filmów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        avg\n",
      "0  4.200606\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT AVG(amount) from film LEFT OUTER JOIN inventory ON film.film_id = inventory.film_id INNER JOIN rental ON inventory.inventory_id = rental.inventory_id INNER JOIN payment ON rental.rental_id = payment.rental_id\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "15. Oblicz i wyświetl liczbę filmów we wszystkich kategoriach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  count\n",
      "0        Horror     56\n",
      "1        Comedy     58\n",
      "2        Sci-Fi     61\n",
      "3         Drama     62\n",
      "4       Foreign     73\n",
      "5      Classics     57\n",
      "6         Games     61\n",
      "7           New     63\n",
      "8        Travel     57\n",
      "9         Music     51\n",
      "10       Action     64\n",
      "11  Documentary     68\n",
      "12       Sports     74\n",
      "13    Animation     66\n",
      "14       Family     69\n",
      "15     Children     60\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT name, COUNT(film_id) from film_category INNER JOIN category on film_category.category_id = category.category_id  GROUP BY name\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "16. Wyświetl liczbę wszystkich klientów pogrupowanych według kraju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  country  count\n",
      "0                Cambodia      2\n",
      "1                  Turkey     15\n",
      "2                 Germany      7\n",
      "3              Madagascar      1\n",
      "4                    Chad      1\n",
      "..                    ...    ...\n",
      "104                 Sudan      2\n",
      "105  United Arab Emirates      3\n",
      "106              Tanzania      3\n",
      "107      French Polynesia      2\n",
      "108              Bulgaria      2\n",
      "\n",
      "[109 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select country, COUNT(customer_id) from customer INNER JOIN address on customer.address_id=address.address_id INNER JOIN city on address.city_id = city.city_id RIGHT OUTER JOIN country on city.country_id = country.country_id GROUP BY country\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "17. Wyświetl informacje o sklepie, który ma więcej niż 100 klientów i mniej niż 300 klientów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [store_id, count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select store.store_id, count(customer_id) from store RIGHT OUTER JOIN address on store.address_id=address.address_id INNER JOIN customer on address.address_id = customer.customer_id group by store.store_id having count(customer_id) > 100 and count(customer_id) < 300\",con=connection)\n",
    "print(df)\n",
    "\n",
    "# coś jest nie tak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_id  count\n",
      "0       NaN    595\n",
      "1       1.0      1\n",
      "2       2.0      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select store.store_id, count(customer_id) from store RIGHT OUTER JOIN address on store.address_id=address.address_id INNER JOIN customer on address.address_id = customer.customer_id group by store.store_id\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_id\n",
      "0         1\n",
      "1         2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select store.store_id from store\",con=connection)\n",
    "print(df)\n",
    "\n",
    "#większość sklepów nie ma id?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "18. Wybierz wszystkich klientów, którzy oglądali filmy ponad 200 godzin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    first_name    last_name   sum\n",
      "0        Scott      Shelley  2916\n",
      "1          Tim         Cary  4476\n",
      "2       Samuel       Marlow  2291\n",
      "3         Vera        Mccoy  2275\n",
      "4       Nelson  Christenson  2119\n",
      "..         ...          ...   ...\n",
      "594      Erica     Matthews  2727\n",
      "595    Stanley    Scroggins  3694\n",
      "596      Ellen      Simpson  2977\n",
      "597      Patsy     Davidson  3513\n",
      "598  Gwendolyn          May  2890\n",
      "\n",
      "[599 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"select first_name, last_name, sum(length) from customer INNER JOIN rental on rental.customer_id=customer.customer_id INNER JOIN inventory on rental.inventory_id = inventory.inventory_id INNER JOIN film on inventory.film_id = film.film_id GROUP BY customer.first_name, last_name having  sum(length) > 200\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "19. Oblicz średnią wartość wypożyczenia filmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           title       avg\n",
      "0                 Frontier Cabin  5.990000\n",
      "1    Arachnophobia Rollercoaster  4.772609\n",
      "2             Cruelty Unforgiven  1.156667\n",
      "3         Intolerable Intentions  5.704286\n",
      "4                  Monsoon Cause  6.101111\n",
      "..                           ...       ...\n",
      "953                  Reef Salute  2.171818\n",
      "954                   Bugsy Song  5.101111\n",
      "955                Orient Closer  4.754706\n",
      "956          Brotherhood Blanket  4.294348\n",
      "957                Boulevard Mob  3.552500\n",
      "\n",
      "[958 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT title, AVG(amount) from film LEFT OUTER JOIN inventory ON film.film_id = inventory.film_id INNER JOIN rental ON inventory.inventory_id = rental.inventory_id INNER JOIN payment ON rental.rental_id = payment.rental_id group by title\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "20. Oblicz średnią wartość długości filmu we wszystkich kategoriach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name         avg\n",
      "0        Horror  112.482143\n",
      "1        Comedy  115.827586\n",
      "2        Sci-Fi  108.196721\n",
      "3         Drama  120.838710\n",
      "4       Foreign  121.698630\n",
      "5      Classics  111.666667\n",
      "6         Games  127.836066\n",
      "7           New  111.126984\n",
      "8        Travel  113.315789\n",
      "9         Music  113.647059\n",
      "10       Action  111.609375\n",
      "11  Documentary  108.750000\n",
      "12       Sports  128.202703\n",
      "13    Animation  111.015152\n",
      "14       Family  114.782609\n",
      "15     Children  109.800000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT name, AVG(length) from category INNER JOIN film_category on film_category.category_id = category.category_id  INNER JOIN film on film_category.film_id = film.film_id GROUP BY name\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "21. Znajdź najdłuższe tytuły filmowe we wszystkich kategoriach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name             title  max\n",
      "0       Children   Crooked Frogmen  143\n",
      "1       Classics    Roots Remember   89\n",
      "2       Classics  Jingle Sagebrush  124\n",
      "3          Games   Moonwalker Fool  184\n",
      "4         Sci-Fi    Bingo Talented  150\n",
      "..           ...               ...  ...\n",
      "995       Family    House Dynamite  109\n",
      "996       Travel     Shining Roses  125\n",
      "997          New   Vanished Garden  142\n",
      "998        Drama      Torque Bound  179\n",
      "999  Documentary     Clerks Angels  164\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT name, title, MAX(length) from category INNER JOIN film_category on film_category.category_id = category.category_id  INNER JOIN film on film_category.film_id = film.film_id GROUP BY name, film.title\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "22. Znajdź najdłuższy film we wszystkich kategoriach. Porównaj wynik z pkt 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           title  length\n",
      "0  Chicago North     185\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT title, length from category INNER JOIN film_category on film_category.category_id = category.category_id  INNER JOIN film on film_category.film_id = film.film_id order BY length desc LIMIT 1\",con=connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie implementacyjne\n",
    "Zaimplementuj wszystkie funkcje w pliku main.py zgodnie z opisem a następnie przetestuj je w notatniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: c:\\Users\\48571\\OneDrive - Akademia Górniczo-Hutnicza im. Stanisława Staszica w Krakowie\\Dokumenty\\ABD-Jakub-Prokop\\lab4\n",
      "plugins: anyio-2.2.0\n",
      "collected 35 items\n",
      "\n",
      "test_main.py ...........................FFF.....                         [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "___________________ test_client_by_sum_length[1000-result2] ___________________\n",
      "\n",
      "sum_min = 1000\n",
      "result =     first_name last_name   sum\n",
      "0        Brian     Wyman  1265\n",
      "1      Antonio      Meek  1451\n",
      "2        Leona    Obrien ...08\n",
      "596      Tammy   Sanders  5065\n",
      "597    Eleanor      Hunt  5360\n",
      "598       Karl      Seal  5388\n",
      "\n",
      "[599 rows x 3 columns]\n",
      "\n",
      "    @pytest.mark.parametrize(\"sum_min,result\", result_client_by_sum_length)\n",
      "    def test_client_by_sum_length(sum_min:Union[int,float], result):\n",
      "        if result is None:\n",
      "            assert main.client_by_sum_length(sum_min) is None, 'Spodziewany wynik: {0}, aktualny {1}. Błedy wejścia.'.format(result, main.client_by_sum_length(sum_min))\n",
      "        else:\n",
      "            test =  main.client_by_sum_length(sum_min)\n",
      ">           pd.testing.assert_frame_equal(result,test), 'Spodziewany wynik: {0}, aktualny {1}. Błędy implementacji.'.format(result, main.client_by_sum_length(sum_min))\n",
      "\n",
      "test_main.py:68: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "pandas\\_libs\\testing.pyx:53: in pandas._libs.testing.assert_almost_equal\n",
      "    ???\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      ">   ???\n",
      "E   AssertionError: DataFrame.iloc[:, 0] (column name=\"first_name\") are different\n",
      "E   \n",
      "E   DataFrame.iloc[:, 0] (column name=\"first_name\") values are different (14.8581 %)\n",
      "E   [index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "E   [left]:  [Brian, Antonio, Leona, Katherine, Tiffany, Jerome, Penny, Lonnie, Dwight, Johnny, Caroline, Allan, Lewis, Lester, Eva, Austin, Joann, Annie, Jonathan, Anita, Eileen, Kenneth, Wayne, Floyd, Paula, Nellie, Vanessa, Jo, Ruben, Oscar, Nelson, Irma, Kristen, Kay, Armando, Sheila, Eugene, Christina, Jeanette, Ann, Rose, Edith, Raul, Lloyd, Kim, Bonnie, Julio, Kirk, Vernon, Nicole, Norma, Vera, Melinda, Willard, Samuel, Leslie, Jill, Jared, Frances, Henry, Allen, Timothy, Alfredo, Corey, Franklin, Frederick, Sean, Daniel, Luis, Laura, Lorraine, Kelly, Tyler, Delores, Roberta, Francisco, Carol, Tony, Adam, Joel, Pamela, Lauren, Terry, Chad, Toni, Chris, Rafael, Darryl, Irene, Adrian, Jacob, Andrea, Anne, Juan, Derrick, Jesus, Anthony, Robert, Yvonne, Alicia, ...]\n",
      "E   [right]: [Brian, Antonio, Leona, Katherine, Tiffany, Jerome, Penny, Lonnie, Dwight, Johnny, Caroline, Allan, Lewis, Lester, Eva, Austin, Joann, Annie, Jonathan, Anita, Eileen, Kenneth, Wayne, Floyd, Paula, Nellie, Vanessa, Jo, Ruben, Nelson, Oscar, Irma, Kristen, Kay, Armando, Sheila, Eugene, Christina, Jeanette, Ann, Rose, Edith, Raul, Lloyd, Kim, Bonnie, Julio, Kirk, Vernon, Nicole, Norma, Vera, Melinda, Willard, Samuel, Leslie, Jill, Jared, Frances, Henry, Allen, Timothy, Alfredo, Corey, Franklin, Frederick, Sean, Daniel, Luis, Laura, Lorraine, Kelly, Tyler, Delores, Francisco, Roberta, Carol, Adam, Tony, Joel, Pamela, Lauren, Terry, Chad, Toni, Chris, Darryl, Rafael, Irene, Adrian, Jacob, Andrea, Anne, Juan, Derrick, Jesus, Anthony, Robert, Yvonne, Alicia, ...]\n",
      "\n",
      "pandas\\_libs\\testing.pyx:168: AssertionError\n",
      "___________________ test_client_by_sum_length[3000-result3] ___________________\n",
      "\n",
      "sum_min = 3000\n",
      "result =     first_name  last_name   sum\n",
      "0      Phillip       Holm  3002\n",
      "1     Kathleen      Adams  3003\n",
      "2        Diana  Alexan...303      Tammy    Sanders  5065\n",
      "304    Eleanor       Hunt  5360\n",
      "305       Karl       Seal  5388\n",
      "\n",
      "[306 rows x 3 columns]\n",
      "\n",
      "    @pytest.mark.parametrize(\"sum_min,result\", result_client_by_sum_length)\n",
      "    def test_client_by_sum_length(sum_min:Union[int,float], result):\n",
      "        if result is None:\n",
      "            assert main.client_by_sum_length(sum_min) is None, 'Spodziewany wynik: {0}, aktualny {1}. Błedy wejścia.'.format(result, main.client_by_sum_length(sum_min))\n",
      "        else:\n",
      "            test =  main.client_by_sum_length(sum_min)\n",
      ">           pd.testing.assert_frame_equal(result,test), 'Spodziewany wynik: {0}, aktualny {1}. Błędy implementacji.'.format(result, main.client_by_sum_length(sum_min))\n",
      "\n",
      "test_main.py:68: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "pandas\\_libs\\testing.pyx:53: in pandas._libs.testing.assert_almost_equal\n",
      "    ???\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      ">   ???\n",
      "E   AssertionError: DataFrame.iloc[:, 0] (column name=\"first_name\") are different\n",
      "E   \n",
      "E   DataFrame.iloc[:, 0] (column name=\"first_name\") values are different (12.0915 %)\n",
      "E   [index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "E   [left]:  [Phillip, Kathleen, Diana, Mario, Stephanie, Gail, Eduardo, Cheryl, Tamara, Dianne, Glenn, Perry, April, Eric, Shelly, Christy, Nancy, Lisa, Ivan, Enrique, Mark, Kristina, Arlene, Douglas, Alan, Bryan, Patricia, Valerie, Greg, Jamie, Ashley, Hilda, Hector, Bill, Matthew, Brenda, Bradley, Gabriel, Terrance, Karen, Evelyn, Eddie, Gilbert, Denise, Beatrice, Ben, Beth, Michele, Jaime, Amanda, Jane, Lucille, Richard, Steven, Randy, Allison, Ian, Brad, Michael, Ruby, Leroy, Jordan, Jessie, Gene, Gloria, Clifton, Cathy, Sonia, Ricky, Jennie, Clifford, Tracey, Felicia, Clarence, Susan, Carole, Reginald, Jay, Dale, Joe, Byron, Rick, Joyce, Andre, Lucy, Ross, Ken, Ted, Javier, Clyde, Amber, Erika, Deborah, Jeffery, Philip, Theodore, Nathan, Dustin, Nina, Lee, ...]\n",
      "E   [right]: [Phillip, Kathleen, Diana, Mario, Stephanie, Gail, Eduardo, Cheryl, Tamara, Dianne, Glenn, Perry, April, Eric, Shelly, Christy, Nancy, Lisa, Enrique, Ivan, Mark, Arlene, Kristina, Douglas, Alan, Bryan, Patricia, Valerie, Greg, Jamie, Ashley, Hilda, Hector, Bill, Matthew, Brenda, Bradley, Gabriel, Terrance, Karen, Eddie, Evelyn, Gilbert, Denise, Beatrice, Ben, Beth, Michele, Jaime, Amanda, Jane, Lucille, Richard, Steven, Randy, Allison, Ian, Brad, Michael, Ruby, Leroy, Jessie, Jordan, Gene, Gloria, Clifton, Cathy, Sonia, Ricky, Jennie, Clifford, Felicia, Tracey, Clarence, Susan, Carole, Reginald, Jay, Dale, Joe, Byron, Rick, Joyce, Andre, Lucy, Ken, Ross, Javier, Ted, Clyde, Amber, Erika, Deborah, Jeffery, Philip, Theodore, Nathan, Dustin, Nina, Lee, ...]\n",
      "\n",
      "pandas\\_libs\\testing.pyx:168: AssertionError\n",
      "___________________ test_client_by_sum_length[2000-result4] ___________________\n",
      "\n",
      "sum_min = 2000\n",
      "result =     first_name last_name   sum\n",
      "0       Eileen      Carr  2031\n",
      "1      Kenneth    Gooden  2033\n",
      "2        Wayne    Truong ...08\n",
      "576      Tammy   Sanders  5065\n",
      "577    Eleanor      Hunt  5360\n",
      "578       Karl      Seal  5388\n",
      "\n",
      "[579 rows x 3 columns]\n",
      "\n",
      "    @pytest.mark.parametrize(\"sum_min,result\", result_client_by_sum_length)\n",
      "    def test_client_by_sum_length(sum_min:Union[int,float], result):\n",
      "        if result is None:\n",
      "            assert main.client_by_sum_length(sum_min) is None, 'Spodziewany wynik: {0}, aktualny {1}. Błedy wejścia.'.format(result, main.client_by_sum_length(sum_min))\n",
      "        else:\n",
      "            test =  main.client_by_sum_length(sum_min)\n",
      ">           pd.testing.assert_frame_equal(result,test), 'Spodziewany wynik: {0}, aktualny {1}. Błędy implementacji.'.format(result, main.client_by_sum_length(sum_min))\n",
      "\n",
      "test_main.py:68: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "pandas\\_libs\\testing.pyx:53: in pandas._libs.testing.assert_almost_equal\n",
      "    ???\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      ">   ???\n",
      "E   AssertionError: DataFrame.iloc[:, 0] (column name=\"first_name\") are different\n",
      "E   \n",
      "E   DataFrame.iloc[:, 0] (column name=\"first_name\") values are different (15.37133 %)\n",
      "E   [index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "E   [left]:  [Eileen, Kenneth, Wayne, Floyd, Paula, Nellie, Vanessa, Jo, Ruben, Oscar, Nelson, Irma, Kristen, Kay, Armando, Sheila, Eugene, Christina, Jeanette, Ann, Rose, Edith, Raul, Lloyd, Kim, Bonnie, Julio, Kirk, Vernon, Nicole, Norma, Vera, Melinda, Willard, Samuel, Leslie, Jill, Jared, Frances, Henry, Allen, Timothy, Alfredo, Corey, Franklin, Frederick, Sean, Daniel, Luis, Laura, Lorraine, Kelly, Tyler, Delores, Roberta, Francisco, Carol, Tony, Adam, Joel, Pamela, Lauren, Terry, Chad, Toni, Chris, Rafael, Darryl, Irene, Adrian, Jacob, Andrea, Anne, Juan, Derrick, Jesus, Anthony, Robert, Yvonne, Alicia, Carlos, Anna, Herbert, Donald, Hugh, Rachel, Francis, Randall, Kevin, Jon, Sam, Mattie, Barbara, Judy, Peggy, Harvey, Lance, Beverly, Peter, Cecil, ...]\n",
      "E   [right]: [Eileen, Kenneth, Wayne, Floyd, Paula, Nellie, Vanessa, Jo, Ruben, Nelson, Oscar, Irma, Kristen, Kay, Armando, Sheila, Eugene, Christina, Jeanette, Ann, Rose, Edith, Raul, Lloyd, Kim, Bonnie, Julio, Kirk, Vernon, Nicole, Norma, Vera, Melinda, Willard, Samuel, Leslie, Jill, Jared, Frances, Henry, Allen, Timothy, Alfredo, Corey, Franklin, Frederick, Sean, Daniel, Luis, Laura, Lorraine, Kelly, Tyler, Delores, Francisco, Roberta, Carol, Adam, Tony, Joel, Pamela, Lauren, Terry, Chad, Toni, Chris, Darryl, Rafael, Irene, Adrian, Jacob, Andrea, Anne, Juan, Derrick, Jesus, Anthony, Robert, Yvonne, Alicia, Anna, Carlos, Herbert, Donald, Hugh, Rachel, Francis, Jon, Kevin, Randall, Sam, Barbara, Mattie, Judy, Peggy, Harvey, Lance, Beverly, Peter, Cecil, ...]\n",
      "\n",
      "pandas\\_libs\\testing.pyx:168: AssertionError\n",
      "============================== warnings summary ===============================\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyreadline\\py3k_compat.py:8\n",
      "  D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyreadline\\py3k_compat.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "    return isinstance(x, collections.Callable)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_main.py::test_client_by_sum_length[1000-result2] - AssertionError...\n",
      "FAILED test_main.py::test_client_by_sum_length[3000-result3] - AssertionError...\n",
      "FAILED test_main.py::test_client_by_sum_length[2000-result4] - AssertionError...\n",
      "=================== 3 failed, 32 passed, 1 warning in 2.76s ===================\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   title                                           languge  \\\n",
      "0          Alter Victory  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "1   Anaconda Confessions  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "2         Argonauts Town  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "3       Bikini Borrowers  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "4       Blackout Private  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "..                   ...                                               ...   \n",
      "61           Tracy Cider  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "62             Turn Star  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "63            Wait Cider  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "64           Watch Tracy  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "65             Wonka Sea  (1,\"English             \",\"2006-02-15 10:02:19\")   \n",
      "\n",
      "         name  \n",
      "0   Animation  \n",
      "1   Animation  \n",
      "2   Animation  \n",
      "3   Animation  \n",
      "4   Animation  \n",
      "..        ...  \n",
      "61  Animation  \n",
      "62  Animation  \n",
      "63  Animation  \n",
      "64  Animation  \n",
      "65  Animation  \n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(main.film_in_category(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name  count\n",
      "0  Animation     66\n"
     ]
    }
   ],
   "source": [
    "print(main.number_films_in_category(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length  count\n",
      "0      100     12\n",
      "1      101      7\n",
      "2      102     11\n",
      "3      103      9\n",
      "4      104      6\n",
      "..     ...    ...\n",
      "81     181     10\n",
      "82     182      6\n",
      "83     183      5\n",
      "84     184      8\n",
      "85     185     10\n",
      "\n",
      "[86 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "print(main.number_film_by_length(100, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      city first_name last_name\n",
      "0  Athenai      Linda  Williams\n"
     ]
    }
   ],
   "source": [
    "print(main.client_from_city('Athenai'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length       avg\n",
      "0      48  4.295389\n"
     ]
    }
   ],
   "source": [
    "print(main.avg_amount_by_length(48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    first_name last_name   sum\n",
      "0        Brian     Wyman  1265\n",
      "1      Antonio      Meek  1451\n",
      "2        Leona    Obrien  1588\n",
      "3    Katherine    Rivera  1615\n",
      "4      Tiffany    Jordan  1667\n",
      "..         ...       ...   ...\n",
      "594      Clara      Shaw  4808\n",
      "595     Wesley      Bull  4808\n",
      "596      Tammy   Sanders  5065\n",
      "597    Eleanor      Hunt  5360\n",
      "598       Karl      Seal  5388\n",
      "\n",
      "[599 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "print(main.client_by_sum_length(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name         avg   sum  min  max\n",
      "0  Action  111.609375  7143   47  185\n"
     ]
    }
   ],
   "source": [
    "print(main.category_statistic_length(\"Action\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2449f63a09368cc443917ae5442932f850f21a0585b7ada999e1eff5200f3b70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('jakubprokop': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
